{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/balienig/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "pathFloderStore = '/home/balienig/Documents/Git/PJ-cPeople/train/trainRnn/imageTrain/walk/'\n",
    "Im_Height = 75\n",
    "Im_Width = 30\n",
    "listName = []\n",
    "ImageSize = 50\n",
    "for folder , dirs, files in os.walk(pathFloderStore):\n",
    "    nameFolder = folder.split('/')\n",
    "    if nameFolder[10] != \"\" :\n",
    "        listName.append(nameFolder[10])\n",
    "\n",
    "# print(listName)\n",
    "listLabel = []\n",
    "numClass = len(listName)\n",
    "for i in range(numClass):\n",
    "    listLabel.append([0]*numClass)\n",
    "    listLabel[i][i] = 1\n",
    "# print(listLabel)\n",
    "training_data = []\n",
    "numRnn = int(((((Im_Height-1)/2)-1)/2)*((((Im_Width-1)/2)-1)/2))\n",
    "for folder , dirs, files in os.walk(pathFloderStore):\n",
    "    for file in files:\n",
    "        path = os.path.join(folder,file)\n",
    "        word_label = path.split('/')\n",
    "        index = listName.index(word_label[10])\n",
    "        # print(index)\n",
    "# print(word_label[10])\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.resize(img,(Im_Height,Im_Width))\n",
    "        # print(img.shape)\n",
    "        training_data.append([np.array(img),listLabel[index]])\n",
    "        # shuffle(training_data)\n",
    "\n",
    "# print(training_data[0][1])\n",
    "\n",
    "listDataSet = []\n",
    "for i in range(1,len(training_data),15):\n",
    "\tlistDs = []\n",
    "\tlistDs.append(training_data[i])\n",
    "\t# print('------------')\n",
    "\tif(i+15 < len(training_data)):\n",
    "\t\tfor j in range(i+1,i+15):\n",
    "\t\t\t# print(np.all(training_data[j-1][1]== training_data[j][1]))\n",
    "\t\t\tif(np.all(training_data[j-1][1] == training_data[j][1])):\n",
    "\t\t\t\tlistDs.append([training_data[j][0],training_data[j][1]])\n",
    "\t\n",
    "\tif(len(listDs) == 15):\n",
    "\t\tlistDataSet.append(listDs)\n",
    "\n",
    "shuffle(listDataSet)\n",
    "\n",
    "\n",
    "frame = []\n",
    "Label = []\n",
    "for i in listDataSet:\n",
    "\tlistFrame = []\n",
    "\tlistLabel = []\n",
    "\tfor j in i:\n",
    "\t\tlistFrame.append(j[0])\n",
    "\t\tlistLabel.append(j[1])\n",
    "\tframe.append(listFrame)\n",
    "\tLabel.append(listLabel)\n",
    "# print(frame[0])\n",
    "print(len(Label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(x, weight, bias):\n",
    "    '''\n",
    "     define rnn cell and prediction\n",
    "    '''\n",
    "\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "    x = tf.split(x, n_input, 1)\n",
    "    \n",
    "\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(cell, x, dtype=tf.float32)\n",
    "    prediction = tf.matmul(outputs[-1], weight) + bias\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-03063d07fda2>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_input = 15\n",
    "training_iters = 1000\n",
    "n_hidden = 512\n",
    "learning_rate = 0.001\n",
    "acc_total = 0\n",
    "loss_total = 0\n",
    "display_step = 100\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_input, 2250])\n",
    "y = tf.placeholder(\"float\", [None, numClass*15*len(Label)])\n",
    "\n",
    "weight = tf.Variable(tf.random_normal([n_hidden, numClass]))\n",
    "bias = tf.Variable(tf.random_normal([numClass]))\n",
    "\n",
    "logits = rnn(x, weight, bias)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "softmax = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "cost = tf.reduce_mean(softmax)\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allresult = []\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    session.run(init_op)\n",
    "\n",
    "    #writer.add_graph(session.graph)\n",
    "    \n",
    "    for i in range(0,len(frame)):\n",
    "        \n",
    "        input_data = np.reshape(frame, [-1, n_input, 2250])\n",
    "        output_data = np.reshape(Label, [1,-1])\n",
    "\n",
    "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, prediction] ,feed_dict={x:input_data, y:output_data})\n",
    "\n",
    "        loss_total += loss\n",
    "        acc_total += acc\n",
    "\n",
    "        print(type(i))\n",
    "        print(type(display_step))\n",
    "        if(i % display_step == 0):\n",
    "            print(\"accuracy: \",acc,\"loss: \",loss,\"predict: \",onehot_pred)\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    save_path = saver.save(session, \"./save_lstm1/model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Elapsed time: \", elapsed(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
